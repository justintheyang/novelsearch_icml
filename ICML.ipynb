{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = pd.read_csv(\"adult.txt\")\n",
    "covtype_df = pd.read_csv(\"covtype.txt\",names=list(range(0,55)))\n",
    "letter_df = pd.read_csv(\"letter-recognition.txt\",names=list(range(0,17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>dat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>218955</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25289</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>181388</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>19</td>\n",
       "      <td>Private</td>\n",
       "      <td>87653</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13038</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>214502</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31629</th>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>79539</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>323055</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15961</th>\n",
       "      <td>47</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>198660</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30516</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>389725</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17434</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>313146</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>185041</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21814</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>116707</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17670</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>161155</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30546</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>45564</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29763</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>199018</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30326</th>\n",
       "      <td>56</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>255386</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Laos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass  fnlwgt      education education-num  \\\n",
       "26398  35            Private  218955      Bachelors            13   \n",
       "25289  33            Private  181388        HS-grad             9   \n",
       "2728   19            Private   87653   Some-college            10   \n",
       "13038  58            Private  214502            9th             5   \n",
       "31629  57   Self-emp-not-inc   79539        HS-grad             9   \n",
       "24992  32            Private  323055        HS-grad             9   \n",
       "15961  47          Local-gov  198660      Bachelors            13   \n",
       "30516  37            Private  389725           12th             8   \n",
       "17434  51            Private  313146        HS-grad             9   \n",
       "4257   46            Private  185041        HS-grad             9   \n",
       "21814  60            Private  116707           11th             7   \n",
       "17670  27            Private  161155        HS-grad             9   \n",
       "30546  47            Private   45564   Some-college            10   \n",
       "29763  41            Private  199018    Prof-school            15   \n",
       "30326  56        Federal-gov  255386   Some-college            10   \n",
       "\n",
       "            marital-status          occupation    relationship  \\\n",
       "26398   Married-civ-spouse               Sales         Husband   \n",
       "25289            Separated       Other-service       Unmarried   \n",
       "2728         Never-married       Other-service       Own-child   \n",
       "13038   Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "31629   Married-civ-spouse     Farming-fishing         Husband   \n",
       "24992   Married-civ-spouse        Craft-repair         Husband   \n",
       "15961   Married-civ-spouse      Prof-specialty         Husband   \n",
       "30516             Divorced        Craft-repair       Own-child   \n",
       "17434   Married-civ-spouse   Machine-op-inspct         Husband   \n",
       "4257    Married-civ-spouse        Craft-repair         Husband   \n",
       "21814             Divorced     Protective-serv   Not-in-family   \n",
       "17670   Married-civ-spouse       Other-service         Husband   \n",
       "30546   Married-civ-spouse     Exec-managerial         Husband   \n",
       "29763   Married-civ-spouse     Exec-managerial         Husband   \n",
       "30326   Married-civ-spouse        Adm-clerical         Husband   \n",
       "\n",
       "                      race      sex capital-gain capital-loss hours-per-week  \\\n",
       "26398                White     Male            0            0             40   \n",
       "25289                White   Female            0            0             40   \n",
       "2728                 White   Female            0            0             25   \n",
       "13038                White     Male            0            0             50   \n",
       "31629   Asian-Pac-Islander     Male            0            0             40   \n",
       "24992                White     Male            0            0             40   \n",
       "15961                White     Male            0            0             40   \n",
       "30516                White     Male            0            0             35   \n",
       "17434                White     Male            0            0             40   \n",
       "4257                 White     Male            0            0             75   \n",
       "21814                White     Male            0            0             40   \n",
       "17670                White     Male            0            0             40   \n",
       "30546                White     Male            0            0             40   \n",
       "29763                White     Male            0            0             40   \n",
       "30326   Asian-Pac-Islander     Male            0            0             40   \n",
       "\n",
       "       native-country  dat  \n",
       "26398   United-States    0  \n",
       "25289   United-States    0  \n",
       "2728    United-States    0  \n",
       "13038   United-States    1  \n",
       "31629   United-States    0  \n",
       "24992   United-States    0  \n",
       "15961   United-States    1  \n",
       "30516   United-States    0  \n",
       "17434   United-States    0  \n",
       "4257    United-States    1  \n",
       "21814   United-States    0  \n",
       "17670   United-States    0  \n",
       "30546   United-States    1  \n",
       "29763   United-States    1  \n",
       "30326            Laos    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mean = SimpleImputer(missing_values=\" ?\", strategy=\"most_frequent\").fit(adult_df)\n",
    "adult_df = pd.DataFrame(imp_mean.transform(adult_df), columns=adult_df.columns)\n",
    "\n",
    "# convert prediction data into binary labels\n",
    "adult_df['dat'] = np.where(adult_df['dat'] == ' >50K',1,0)\n",
    "adult_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_column = covtype_df[54]\n",
    "positive_label = pred_column.value_counts().index[0]\n",
    "\n",
    "# convert prediction data into binary labels\n",
    "pred_column = np.where(pred_column == positive_label, 1, 0)\n",
    "\n",
    "covtype_df.drop(columns=[54],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151449</th>\n",
       "      <td>0.548774</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.137437</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.798089</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.282169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423036</th>\n",
       "      <td>0.467734</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.088762</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.211184</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.350394</td>\n",
       "      <td>0.354384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219961</th>\n",
       "      <td>0.712356</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136006</td>\n",
       "      <td>0.215762</td>\n",
       "      <td>0.474919</td>\n",
       "      <td>0.870079</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.260560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439465</th>\n",
       "      <td>0.600300</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.030064</td>\n",
       "      <td>0.224806</td>\n",
       "      <td>0.367711</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.681102</td>\n",
       "      <td>0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81825</th>\n",
       "      <td>0.523762</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.137437</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.579036</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.972441</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.503973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123250</th>\n",
       "      <td>0.454727</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.060845</td>\n",
       "      <td>0.237726</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.964567</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.419211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391011</th>\n",
       "      <td>0.660830</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.369363</td>\n",
       "      <td>0.361757</td>\n",
       "      <td>0.280315</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>0.129932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129500</th>\n",
       "      <td>0.459730</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.042949</td>\n",
       "      <td>0.224806</td>\n",
       "      <td>0.345230</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.933071</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.370974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573896</th>\n",
       "      <td>0.396698</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.085898</td>\n",
       "      <td>0.306202</td>\n",
       "      <td>0.399747</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.169106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415547</th>\n",
       "      <td>0.736868</td>\n",
       "      <td>0.286111</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.349320</td>\n",
       "      <td>0.291990</td>\n",
       "      <td>0.194042</td>\n",
       "      <td>0.964567</td>\n",
       "      <td>0.854331</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.345323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "151449  0.548774  0.716667  0.106061  0.137437  0.217054  0.798089  0.803150   \n",
       "423036  0.467734  0.125000  0.348485  0.088762  0.267442  0.211184  0.862205   \n",
       "219961  0.712356  0.108333  0.136364  0.136006  0.215762  0.474919  0.870079   \n",
       "439465  0.600300  0.922222  0.196970  0.030064  0.224806  0.367711  0.748031   \n",
       "81825   0.523762  0.638889  0.121212  0.137437  0.279070  0.579036  0.818898   \n",
       "123250  0.454727  0.469444  0.181818  0.060845  0.237726  0.295068  0.901575   \n",
       "391011  0.660830  0.586111  0.257576  0.369363  0.361757  0.280315  0.803150   \n",
       "129500  0.459730  0.875000  0.030303  0.042949  0.224806  0.345230  0.838583   \n",
       "573896  0.396698  0.572222  0.500000  0.085898  0.306202  0.399747  0.708661   \n",
       "415547  0.736868  0.286111  0.242424  0.349320  0.291990  0.194042  0.964567   \n",
       "\n",
       "              7         8         9   ...   45   46   47   48   49   50   51  \\\n",
       "151449  0.960630  0.704724  0.282169  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "423036  0.724409  0.350394  0.354384  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "219961  0.862205  0.523622  0.260560  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "439465  0.881890  0.681102  0.093963  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "81825   0.972441  0.692913  0.503973  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "123250  0.964567  0.570866  0.419211  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "391011  1.000000  0.712598  0.129932  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "129500  0.933071  0.637795  0.370974  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "573896  0.976378  0.708661  0.169106  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "415547  0.854331  0.377953  0.345323  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         52   53  54  \n",
       "151449  0.0  0.0   0  \n",
       "423036  0.0  0.0   1  \n",
       "219961  0.0  0.0   0  \n",
       "439465  0.0  0.0   0  \n",
       "81825   0.0  0.0   1  \n",
       "123250  0.0  0.0   1  \n",
       "391011  0.0  0.0   0  \n",
       "129500  0.0  0.0   0  \n",
       "573896  0.0  0.0   0  \n",
       "415547  0.0  0.0   0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(covtype_df)\n",
    "covtype_df = pd.DataFrame(scaler.transform(covtype_df),columns=covtype_df.columns)\n",
    "covtype_df.insert(54,54,pred_column,True)\n",
    "covtype_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_col,pred_column = letter_df[0], letter_df[16]\n",
    "letter_df.drop(columns=[0,16],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10073</th>\n",
       "      <td>G</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18802</th>\n",
       "      <td>H</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11735</th>\n",
       "      <td>X</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>R</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>P</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16603</th>\n",
       "      <td>P</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>T</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6   \\\n",
       "10073  G  0.400000  0.733333  0.400000  0.533333  0.333333  0.400000   \n",
       "18802  H  0.333333  0.600000  0.533333  0.466667  0.533333  0.466667   \n",
       "11735  X  0.133333  0.266667  0.266667  0.200000  0.133333  0.666667   \n",
       "8550   Q  0.333333  0.466667  0.333333  0.600000  0.400000  0.466667   \n",
       "6188   R  0.200000  0.600000  0.266667  0.400000  0.133333  0.333333   \n",
       "5712   P  0.333333  0.733333  0.533333  0.533333  0.333333  0.400000   \n",
       "16603  P  0.466667  0.733333  0.600000  0.533333  0.533333  0.400000   \n",
       "7710   Y  0.200000  0.666667  0.333333  0.466667  0.066667  0.466667   \n",
       "12361  T  0.066667  0.000000  0.066667  0.000000  0.000000  0.466667   \n",
       "3922   Y  0.266667  0.466667  0.400000  0.333333  0.200000  0.333333   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "10073  0.400000  0.400000  0.400000  0.666667  0.400000  0.866667  0.266667   \n",
       "18802  0.466667  0.400000  0.400000  0.466667  0.400000  0.533333  0.200000   \n",
       "11735  0.466667  0.066667  0.533333  0.666667  0.200000  0.466667  0.133333   \n",
       "8550   0.666667  0.266667  0.200000  0.466667  0.666667  0.666667  0.200000   \n",
       "6188   0.666667  0.533333  0.266667  0.466667  0.266667  0.600000  0.200000   \n",
       "5712   0.733333  0.200000  0.400000  0.933333  0.466667  0.266667  0.000000   \n",
       "16603  0.533333  0.466667  0.266667  0.533333  0.466667  0.600000  0.200000   \n",
       "7710   0.800000  0.066667  0.266667  0.466667  0.800000  0.533333  0.000000   \n",
       "12361  0.866667  0.066667  0.266667  0.466667  0.666667  0.533333  0.000000   \n",
       "3922   0.600000  0.066667  0.466667  0.533333  0.800000  0.600000  0.066667   \n",
       "\n",
       "             14        15  16  17  18  \n",
       "10073  0.600000  0.400000   8   0   1  \n",
       "18802  0.533333  0.200000   8   0   1  \n",
       "11735  0.466667  0.200000   8   0   0  \n",
       "8550   0.666667  0.400000   7   0   0  \n",
       "6188   0.466667  0.400000  11   0   0  \n",
       "5712   0.666667  0.200000   8   0   0  \n",
       "16603  0.600000  0.466667   9   0   0  \n",
       "7710   0.666667  0.000000   8   0   0  \n",
       "12361  0.533333  0.000000   8   0   0  \n",
       "3922   0.733333  0.133333   7   0   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(letter_df)\n",
    "letter_df = pd.DataFrame(scaler.transform(letter_df),columns=letter_df.columns)\n",
    "letter_df.insert(0,0,letter_col,True)\n",
    "letter_df.insert(16,16,pred_column,True)\n",
    "\n",
    "# two ways to make binary classification labels\n",
    "letter_df_p1 = np.where(letter_df[0] == 'O', 1, 0)\n",
    "letter_df_p2 = np.where(letter_df[0].isin([chr(x) for x in range(ord('A'), ord('M') + 1)]), 1, 0)\n",
    "letter_df.insert(17,17,letter_df_p1,True)\n",
    "letter_df.insert(18,18,letter_df_p2,True)\n",
    "\n",
    "\n",
    "letter_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-700440aa295b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovtype_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "# parameters = {'C':[1],'penalty':['l2']}\n",
    "X = covtype_df.drop(columns=[0])\n",
    "y = np.where(covtype_df[16] == 2,1,0)\n",
    "log_reg = LogisticRegression()\n",
    "clf = GridSearchCV(estimator=log_reg,param_grid=parameters)\n",
    "clf.fit(X,y)\n",
    "print(clf.score(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1374, in fit\n",
      "    \" class: %r\" % classes_[0])\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = adult_df[['workclass', 'marital-status', 'occupation', 'relationship']]\n",
    "y = np.where(adult_df.iloc[:,-1] == ' >50K',1,0)\n",
    "\n",
    "column_trans = make_column_transformer((OneHotEncoder(handle_unknown='ignore'),\n",
    "                                        ['workclass', 'marital-status', 'occupation']),\n",
    "                                      (OrdinalEncoder(), ['relationship']),\n",
    "                                      remainder='drop')\n",
    "logreg = LogisticRegression()\n",
    "pipe = make_pipeline(column_trans, logreg)\n",
    "cross_val_score(pipe, X, y, cv=10, scoring='f1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
